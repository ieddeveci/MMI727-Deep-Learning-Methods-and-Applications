{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transforms = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(p = 0.5), \n",
    "                                                      torchvision.transforms.Resize(size = (100, 100)), \n",
    "                                                      torchvision.transforms.ToTensor()])\n",
    "validation_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(size = (100, 100)), \n",
    "                                                        torchvision.transforms.ToTensor()])\n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.Resize(size = (100, 100)), \n",
    "                                                  torchvision.transforms.ToTensor()])\n",
    "\n",
    "training_dataset = torchvision.datasets.ImageFolder(root = \"TRAINING SET PATH\", transform = training_transforms)\n",
    "validation_dataset = torchvision.datasets.ImageFolder(root = \"VALIDATION SET PATH\", transform = validation_transforms)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = \"TEST SET PATH\", transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "training_dataloader   = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader       = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.batchnorm1 = torch.nn.BatchNorm2d(num_features=16)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.batchnorm2 = torch.nn.BatchNorm2d(num_features=32)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.batchnorm3 = torch.nn.BatchNorm2d(num_features=32)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(32, 16)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.fc2 = torch.nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = ConvNet().to('cuda')\n",
    "test_input = torch.randn(16, 3, 100, 100, device='cuda')\n",
    "test_output = convnet(test_input)\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(convnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(neuralnet, dataloader):\n",
    "    \n",
    "    neuralnet.eval()\n",
    "    \n",
    "    true_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    device = next(neuralnet.parameters()).device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = neuralnet(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_prediction += labels.size(0)\n",
    "            true_prediction += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = true_prediction / total_prediction\n",
    "    \n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = check_accuracy(convnet, test_dataloader)\n",
    "print(f'Test accuracy before training: {test_accuracy * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(neuralnet, dataloader, optimizer, loss_fn):\n",
    "\n",
    "    total_loss = 0.0 \n",
    "    \n",
    "    neuralnet.train()\n",
    "    \n",
    "    for imgs_batch, labels_batch in dataloader:\n",
    "        imgs_batch, labels_batch = imgs_batch.to(\"cuda\"), labels_batch.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = neuralnet(imgs_batch)\n",
    "        loss = loss_fn(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy_list = []\n",
    "validation_accuracy_list = []\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "scheduling = 2\n",
    "earlystop = 5\n",
    "best_val_accuracy = 0.0\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch_no in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch_no + 1}...')\n",
    "    \n",
    "    train_one_epoch(convnet, training_dataloader, optimizer, loss_fn)\n",
    "    \n",
    "    training_accuracy = check_accuracy(convnet, training_dataloader)\n",
    "    print(f'Training accuracy: {training_accuracy * 100 :.2f}%')\n",
    "    validation_accuracy = check_accuracy(convnet, validation_dataloader)\n",
    "    print(f'Validation accuracy: {validation_accuracy * 100 :.2f}%')\n",
    "    \n",
    "    training_accuracy_list.append(training_accuracy)\n",
    "    validation_accuracy_list.append(validation_accuracy)\n",
    "\n",
    "    if validation_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = validation_accuracy\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "\n",
    "    if no_improvement >= scheduling:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "        print(f'Learning rate reduced to {param_group[\"lr\"]}')\n",
    "    \n",
    "    if no_improvement >= earlystop:\n",
    "        print(f'No improvement for {earlystop} epochs.')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_accuracy_list)\n",
    "plt.plot(validation_accuracy_list)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = check_accuracy(convnet, test_dataloader)\n",
    "print(f'Test accuracy after training: {test_accuracy * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(convnet.state_dict(), \"convNet_for_imageClassification.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
